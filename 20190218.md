到今天终于梳理出了Visual Saliency Based on Multiscale deep features的实现思路...  

* 下载数据集
	* 已经下载MSRB,其中包括5000张图的原图以及二值化的显著性区域标注
* 完成基于图的图像分割
	* 实现原图的分割结果到binary saliency labels的对应  
	* 挑选其中完全（80%以上的像素）属于背景或者显著性物体的区域作为训练网络的数据  
	* 能够快速确定一个区域及其直接相邻的区域  
* 用keras实现AlexNet在ImageNet上的训练 或者换一个数据集吧...  
* 完成在三个CNN网络的顶部加上两个全连接层及一个输出层，完成特征向量到显著性分数的预测
* ...

还是得先读懂图像分割的代码啊...  